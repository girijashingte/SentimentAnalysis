{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>Sentiment Analysis on IMDB movie reviews using TF-IDF weighting scheme, Sentiment Score and Mutlinomial Naives Bayes Classification</u></h3>\n",
    "<h4>Girija Prakash Shingte<br>shingte.girija@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the data by removing stopwords, special symbols and digits\n",
    "def data_cleaning(file_name):\n",
    "    reviews = open(file_name,'r')\n",
    "    list_of_stopwords = list(set(stopwords.words()))\n",
    "    list_of_digits = re.compile('[0-9]')\n",
    "    rev = []\n",
    "    lbl = []\n",
    "    for review in reviews:\n",
    "        sent = review.split('\\t')[0]\n",
    "        label = review.split('\\t')[1]\n",
    "        wordlist = []\n",
    "        sent = sent.split(' ')\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            #remove stopwords\n",
    "            if(word not in list_of_stopwords\n",
    "               #check if digits are present\n",
    "               and not list_of_digits.search(word)\n",
    "               #check if special symbols are present\n",
    "               and word.isalnum()\n",
    "               #check if length of word is not less than 1\n",
    "               and not len(word)<=1):\n",
    "                wordlist.append(word)\n",
    "        #check if the wordlist is not empty\n",
    "        if(len(wordlist)>1):\n",
    "            #convert wordlist back to sentence and append to review list\n",
    "            rev.append(' '.join(wordlist))\n",
    "            #append label\n",
    "            #label is converted from string to integer\n",
    "            lbl.append(int(label.rstrip('\\n')))\n",
    "    return(rev,lbl)\n",
    "\n",
    "rev, lbl = data_cleaning('imdb_labelled.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find tf-idf score for all the terms in every sentence and sum it up\n",
    "def find_tfidfscore(rev):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(rev).todense()\n",
    "    X = pd.DataFrame(X, columns=vectorizer.get_feature_names())\n",
    "    X['total'] = X.sum(axis=1)\n",
    "    tfidf = list(X['total'])\n",
    "    return(tfidf)\n",
    "    \n",
    "tfidf = find_tfidfscore(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find sentiment score for each term in the sentence: positive, negative and neutrality\n",
    "def find_sentimentscore(rev):\n",
    "    positive_sentiment = []\n",
    "    negative_sentiment = []\n",
    "    neutrality = []\n",
    "    for review in rev:\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        neutral = 0\n",
    "        pos = pos_tag(review)\n",
    "        for item in pos:\n",
    "            synset = swn.senti_synsets(item[0])\n",
    "            for x in synset:\n",
    "                positive+= x.pos_score()\n",
    "                negative+= x.neg_score()\n",
    "                neutral+= x.obj_score()\n",
    "        positive_sentiment.append(round(positive,3))\n",
    "        negative_sentiment.append(round(negative,3))\n",
    "        neutrality.append(round(neutral))\n",
    "    return(positive_sentiment, negative_sentiment, neutrality)\n",
    "\n",
    "positive_sentiment, negative_sentiment, neutrality = find_sentimentscore(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>neutrality</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.919818</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.623103</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.25</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.927078</td>\n",
       "      <td>6.375</td>\n",
       "      <td>5.75</td>\n",
       "      <td>554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.987891</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.935115</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.75</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tfidf  positive_sentiment  negative_sentiment  neutrality  label\n",
       "0  1.919818               1.000                1.50         124      0\n",
       "1  2.623103               2.375                2.25         208      0\n",
       "2  3.927078               6.375                5.75         554      0\n",
       "3  1.987891               1.000                1.50         134      0\n",
       "4  2.935115               3.000                1.75         245      1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "df = pd.DataFrame()\n",
    "df['tfidf'] = tfidf\n",
    "df['positive_sentiment'] = positive_sentiment\n",
    "df['negative_sentiment'] = negative_sentiment\n",
    "df['neutrality'] = neutrality\n",
    "df['label'] = lbl\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "X = df.drop('label',axis=1)\n",
    "y = df[['label']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.9, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model\n",
    "naivebayes = MultinomialNB(alpha = 0.9)\n",
    "naivebayes.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict result\n",
    "y_pred = list(naivebayes.predict(X_test))\n",
    "y_test = list(y_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results:</h3>\n",
    "<ul>\n",
    "    <li>Accuracy using TF-IDF weighting and Sentiment Score is poor</li>\n",
    "</ul>  \n",
    "<h3>Scope of Improvement:</h3>\n",
    "<ul>\n",
    "    <li>Using a different classifier(SVM, Logistic Regression)\n",
    "    <li>Using CountVectorizer in place of TF-IDF weighting scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>References:</h3>\n",
    "<ul>\n",
    "<li>Uci.edu. (2015). UCI Machine Learning Repository: Sentiment Labelled Sentences Data Set. [online] Available at: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
